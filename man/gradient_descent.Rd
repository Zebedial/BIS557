% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gradient_descent.R
\name{gradient_descent}
\alias{gradient_descent}
\title{Gradient Descent}
\usage{
gradient_descent(
  formula,
  data,
  contrasts = NULL,
  gamma = 1e-04,
  maxiter = 1e+06,
  tolt = 1e-12
)
}
\arguments{
\item{formula}{A symbolic description of the model to be fitted. This should be a formula class argument.}

\item{data}{Specification of a dataframe that contains the variables in the model.}

\item{contrasts}{A list of contrasts.}

\item{gamma}{Specification of a learning rate that adjust the OLS estimates along gradient.}

\item{maxiter}{Maximum number of iterations for the updating process of OLS estimates.}

\item{tolt}{A tolerance that bounds the difference between the current SSR and the updated SSR.}
}
\value{
A list of component that imitates the output of lm() function. Including estimated coefficients for predictors specified in the formula.
also may return a warning if the iterations exceed the maximum iteration number.
}
\description{
Implement gradient descent for ordinary least square. Gradient descent can only handle design matrix with full rank.
For design matrix with problem of collinearity, if perfect collinearity presents, the OLS estimate computed by gradient descent
contains redundant estimate corresponding to variables should be omitted; For other cases with strong collinearity, the method may not be
convergent (i.e. the lm_patho data). This function will pass the data to the the function "linear_model" when it cannot be able to handle
the problem
}
\examples{
data(iris)
gradient_descent(Sepal.Length ~ ., iris)
}
